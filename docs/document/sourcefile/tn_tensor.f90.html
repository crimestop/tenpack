<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
   
    <meta name="description" content="Documentation for TNSG">
   
    <meta name="author" content="Wang Chao & Dong Shaojun" >
    <link rel="icon" href="../favicon.png">

    <title>tn_tensor.f90 &ndash; TNSG</title>

    <link href="../css/bootstrap.min.css" rel="stylesheet">
    <link href="../css/pygments.css" rel="stylesheet">
    <link href="../css/font-awesome.min.css" rel="stylesheet">
    <link href="../css/local.css" rel="stylesheet">
    
    

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    
    <script src="../js/jquery-2.1.3.min.js"></script>
    <script src="../js/svg-pan-zoom.min.js"></script>

  </head>

  <body>

    <!-- Fixed navbar -->
    <nav class="navbar navbar-inverse navbar-fixed-top">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="../index.html">TNSG </a>
        </div>
        <div id="navbar" class="navbar-collapse collapse">
          <ul class="nav navbar-nav">
        
            <li class="dropdown hidden-xs visible-sm visible-md hidden-lg">
              <a href="#" class="dropdown-toggle"
              data-toggle="dropdown" role="button"
              aria-haspopup="true"
     aria-expanded="false">Contents <span class="caret"></span></a>
        <ul class="dropdown-menu">
          
              
            <li><a href="../lists/files.html">Source Files</a></li>
        
        
        
            <li><a href="../lists/modules.html">Modules</a></li>
        
            
                                
            <li><a href="../lists/procedures.html">Procedures</a></li>
        
               
            <li><a href="../lists/types.html">Derived Types</a></li>
        
        
            </ul>
            </li>


<li class="visible-xs hidden-sm visible-lg"><a href="../lists/files.html">Source Files</a></li>



<li class="visible-xs hidden-sm visible-lg"><a href="../lists/modules.html">Modules</a></li>



<li class="visible-xs hidden-sm visible-lg"><a href="../lists/procedures.html">Procedures</a></li>

                             
<li class="visible-xs hidden-sm visible-lg"><a href="../lists/types.html">Derived Types</a></li>


          </ul>
        
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">
    
  
  <div class="row">
    <h1>tn_tensor.f90
    <small>Source File</small>
    
    </h1>
    
<div class="row">
  <div class="col-lg-12">
<div class="well well-sm">
  <ul class="list-inline" style="margin-bottom:0px;display:inline">
     
     
     
     
    
    
     <li><i class="fa fa-list-ol"></i>
       <a data-toggle="tooltip"
    data-placement="bottom" data-html="true"
    title=" 5.1% of total for source files.">417 statements</a>
     </li> 
     
     
     
    <li><i class="fa fa-code"></i><a href="../src/tn_tensor.f90"> Source File</a></li>
     
     
  </ul>
  <ol class="breadcrumb in-well text-right">
  
    
  
     <li class="active">tn_tensor.f90</li>
  </ol>
</div>
</div>
</div>
<script>
  $(function () {
  $('[data-toggle="tooltip"]').tooltip()
  })
</script>

  </div>
  <div class="row">
    <div class="col-md-3 hidden-xs hidden-sm visible-md visible-lg">
    
<div id="sidebar">
  
<h3>Contents</h3>
 







<div class="panel panel-primary">
  <div class="panel-heading text-left"><h3 class="panel-title"><a data-toggle="collapse" href="#mods-0">Modules</a></h3></div>
  <div id="mods-0" class="panel-collapse collapse">
    <div class="list-group">
      
      <a class="list-group-item" href="../module/tn_tensor_type.html">tn_tensor_type</a>
      
    </div>
  </div>
</div>
















<div class="panel panel-primary">
  <div class="panel-heading text-left"><h3 class="panel-title">Source Code</h3></div>
  <div class="list-group">
    <a class="list-group-item" href="../sourcefile/tn_tensor.f90.html#src">tn_tensor.f90</a>
  </div>
</div>



</div>

    </div>
    <div class="col-md-9" id='text'>
      
      <br>
    
      
      

    <section class="visible-xs visible-sm hidden-md">
      
<h3>Contents</h3>
 







<div class="panel panel-primary">
  <div class="panel-heading text-left"><h3 class="panel-title"><a data-toggle="collapse" href="#mods-1">Modules</a></h3></div>
  <div id="mods-1" class="panel-collapse collapse">
    <div class="list-group">
      
      <a class="list-group-item" href="../module/tn_tensor_type.html">tn_tensor_type</a>
      
    </div>
  </div>
</div>
















<div class="panel panel-primary">
  <div class="panel-heading text-left"><h3 class="panel-title">Source Code</h3></div>
  <div class="list-group">
    <a class="list-group-item" href="../sourcefile/tn_tensor.f90.html#src">tn_tensor.f90</a>
  </div>
</div>



    </section>
    <br class="visible-xs visible-sm hidden-md">

    <section>
      <h2><span class="anchor" id="src"></span>Source Code</h2>
    <div class="hl"><pre><span></span><a name="ln-1"></a><span class="k">MODULE </span><span class="n">tn_tensor_type</span>
<a name="ln-2"></a><span class="k">use </span><span class="n">error</span> 
<a name="ln-3"></a><span class="k">use </span><span class="n">tools</span>
<a name="ln-4"></a><span class="k">use </span><span class="n">tensor_network</span>
<a name="ln-5"></a><span class="k">use </span><span class="n">tensor_type</span>
<a name="ln-6"></a><span class="k">implicit none</span>
<a name="ln-7"></a><span class="k">private</span>
<a name="ln-8"></a>
<a name="ln-9"></a><span class="k">type</span><span class="p">,</span> <span class="k">extends</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span><span class="kd">::</span> <span class="n">tn_tensor</span>
<a name="ln-10"></a>	<span class="k">private</span>
<a name="ln-11"></a>
<a name="ln-12"></a><span class="k">	type</span><span class="p">(</span><span class="n">group</span><span class="p">)</span><span class="kd">::</span><span class="n">grp</span>
<a name="ln-13"></a>
<a name="ln-14"></a>	<span class="k">contains</span>
<a name="ln-15"></a><span class="k">	private</span>
<a name="ln-16"></a><span class="k">	procedure</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span> <span class="n">get_info</span>
<a name="ln-17"></a>	<span class="k">procedure</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span> <span class="n">draw</span>
<a name="ln-18"></a>	<span class="k">procedure</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span> <span class="n">empty</span>
<a name="ln-19"></a>	<span class="k">procedure</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span> <span class="n">absorb</span>
<a name="ln-20"></a>	<span class="k">procedure</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span> <span class="n">absorb_with_env</span>
<a name="ln-21"></a>	<span class="k">procedure</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span> <span class="n">absorb_just_env</span>
<a name="ln-22"></a>	<span class="k">procedure</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span> <span class="n">take</span>
<a name="ln-23"></a>	<span class="k">procedure</span><span class="kd">::</span> <span class="n">absorb_all0</span>
<a name="ln-24"></a>	<span class="k">procedure</span><span class="kd">::</span> <span class="n">absorb_all1</span>
<a name="ln-25"></a>	<span class="k">generic</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span> <span class="n">absorb_all</span><span class="o">=&gt;</span><span class="n">absorb_all0</span><span class="p">,</span><span class="n">absorb_all1</span>
<a name="ln-26"></a>	<span class="k">procedure</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span> <span class="n">belong</span>
<a name="ln-27"></a>	<span class="k">procedure</span><span class="kd">::</span> <span class="n">take_except_pos</span>
<a name="ln-28"></a>	<span class="k">procedure</span><span class="kd">::</span> <span class="n">take_except_name</span>
<a name="ln-29"></a>	<span class="k">procedure</span><span class="kd">::</span> <span class="n">take_except_path</span>
<a name="ln-30"></a>	<span class="k">procedure</span><span class="kd">::</span> <span class="n">take_except_group</span>
<a name="ln-31"></a>	<span class="k">generic</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span><span class="n">take_except</span><span class="o">=&gt;</span><span class="n">take_except_pos</span><span class="p">,</span><span class="n">take_except_name</span><span class="p">,</span><span class="n">take_except_path</span><span class="p">,</span><span class="n">take_except_group</span>
<a name="ln-32"></a>	<span class="k">procedure</span><span class="kd">::</span><span class="n">absorb0_except_pos</span>
<a name="ln-33"></a>	<span class="k">procedure</span><span class="kd">::</span><span class="n">absorb1_except_pos</span>
<a name="ln-34"></a>	<span class="k">procedure</span><span class="kd">::</span><span class="n">absorb0_except_name</span>
<a name="ln-35"></a>	<span class="k">generic</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span><span class="n">absorb_except</span><span class="o">=&gt;</span><span class="n">absorb0_except_pos</span><span class="p">,</span><span class="n">absorb0_except_name</span><span class="p">,</span><span class="n">absorb1_except_pos</span>
<a name="ln-36"></a>	<span class="k">procedure</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span><span class="n">invert_bond</span>
<a name="ln-37"></a>	<span class="k">procedure</span><span class="p">,</span><span class="k">public</span><span class="kd">::</span><span class="n">get_lattice_link</span>
<a name="ln-38"></a>
<a name="ln-39"></a><span class="k">end type  </span>
<a name="ln-40"></a>
<a name="ln-41"></a><span class="k">interface </span><span class="n">assignment</span><span class="p">(</span><span class="o">=</span><span class="p">)</span>
<a name="ln-42"></a>	<span class="k">module procedure </span><span class="n">assignmentDTN</span>
<a name="ln-43"></a>	<span class="k">module procedure </span><span class="n">assignmentZTN</span>
<a name="ln-44"></a>	<span class="k">module procedure </span><span class="n">assignmentTTN</span>
<a name="ln-45"></a>	<span class="k">module procedure </span><span class="n">assignmentTNTN</span>
<a name="ln-46"></a><span class="k">end interface</span>
<a name="ln-47"></a>
<a name="ln-48"></a><span class="k">interface </span><span class="n">operator</span><span class="p">(</span><span class="o">*</span><span class="p">)</span>
<a name="ln-49"></a>	<span class="k">module procedure </span><span class="n">scale_tn</span>
<a name="ln-50"></a><span class="k">end interface</span>
<a name="ln-51"></a>
<a name="ln-52"></a><span class="k">interface </span><span class="n">operator</span><span class="p">(</span><span class="o">/</span><span class="p">)</span>
<a name="ln-53"></a>	<span class="k">module procedure </span><span class="n">divide_tn</span>
<a name="ln-54"></a><span class="k">end interface</span>
<a name="ln-55"></a>
<a name="ln-56"></a><span class="k">interface </span><span class="n">operator</span><span class="p">(.</span><span class="n">con</span><span class="p">.)</span>
<a name="ln-57"></a>	<span class="k">module procedure </span><span class="n">conjugate_tn</span>
<a name="ln-58"></a><span class="k">end interface</span>
<a name="ln-59"></a>
<a name="ln-60"></a><span class="k">interface </span><span class="n">absorb_all_rt</span>
<a name="ln-61"></a>	<span class="k">module procedure </span><span class="n">absorb_all0_rt</span>
<a name="ln-62"></a>	<span class="k">module procedure </span><span class="n">absorb_all1_rt</span>
<a name="ln-63"></a><span class="k">end interface</span>
<a name="ln-64"></a>
<a name="ln-65"></a><span class="k">interface </span><span class="n">TNcontract</span>
<a name="ln-66"></a>	<span class="k">module procedure </span><span class="n">contract_TNTN</span>
<a name="ln-67"></a><span class="k">end interface</span>
<a name="ln-68"></a>
<a name="ln-69"></a><span class="kt">logical</span> <span class="kd">::</span> <span class="n">draw_mode</span><span class="o">=</span><span class="p">.</span><span class="n">false</span><span class="p">.</span>
<a name="ln-70"></a>
<a name="ln-71"></a><span class="k">public </span><span class="n">tn_tensor</span><span class="p">,</span><span class="n">assignment</span><span class="p">(</span><span class="o">=</span><span class="p">),</span><span class="n">operator</span><span class="p">(</span><span class="o">*</span><span class="p">),</span><span class="n">operator</span><span class="p">(</span><span class="o">/</span><span class="p">),</span><span class="n">operator</span><span class="p">(.</span><span class="n">con</span><span class="p">.),</span><span class="n">absorb_rt</span><span class="p">,</span><span class="n">absorb_all_rt</span><span class="p">,</span><span class="n">TNcontract</span><span class="p">,&amp;</span>
<a name="ln-72"></a>	<span class="n">tn_draw_on</span><span class="p">,</span><span class="n">tn_draw_off</span>
<a name="ln-73"></a>
<a name="ln-74"></a><span class="k">contains</span>
<a name="ln-75"></a>
<a name="ln-76"></a><span class="k">subroutine </span><span class="n">tn_draw_on</span><span class="p">()</span>
<a name="ln-77"></a>	<span class="n">draw_mode</span><span class="o">=</span><span class="p">.</span><span class="n">true</span><span class="p">.</span>
<a name="ln-78"></a><span class="k">end subroutine</span>
<a name="ln-79"></a>
<a name="ln-80"></a><span class="k">subroutine </span><span class="n">tn_draw_off</span><span class="p">()</span>
<a name="ln-81"></a>	<span class="n">draw_mode</span><span class="o">=</span><span class="p">.</span><span class="n">false</span><span class="p">.</span>
<a name="ln-82"></a><span class="k">end subroutine</span>
<a name="ln-83"></a>
<a name="ln-84"></a><span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">)</span> <span class="k">function </span><span class="n">scale_tn</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">mul</span><span class="p">)</span>
<a name="ln-85"></a>
<a name="ln-86"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-87"></a>	<span class="k">class</span><span class="p">(</span><span class="o">*</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">mul</span>
<a name="ln-88"></a>
<a name="ln-89"></a>	<span class="n">scale_tn</span><span class="p">%</span><span class="n">grp</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">grp</span>
<a name="ln-90"></a>
<a name="ln-91"></a>	<span class="k">select type</span><span class="p">(</span><span class="n">mul</span><span class="p">)</span>
<a name="ln-92"></a>	<span class="k">type is</span><span class="p">(</span><span class="kt">real</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<a name="ln-93"></a>		<span class="n">scale_tn</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="o">*</span><span class="n">mul</span>
<a name="ln-94"></a>	<span class="k">type is</span><span class="p">(</span><span class="kt">real</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<a name="ln-95"></a>		<span class="n">scale_tn</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="o">*</span><span class="n">mul</span>
<a name="ln-96"></a>	<span class="k">type is</span><span class="p">(</span><span class="kt">complex</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<a name="ln-97"></a>		<span class="n">scale_tn</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="o">*</span><span class="n">mul</span>
<a name="ln-98"></a>	<span class="k">type is</span><span class="p">(</span><span class="kt">complex</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<a name="ln-99"></a>		<span class="n">scale_tn</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="o">*</span><span class="n">mul</span>
<a name="ln-100"></a>	<span class="k">end select</span>
<a name="ln-101"></a>
<a name="ln-102"></a><span class="k">end function</span>
<a name="ln-103"></a>
<a name="ln-104"></a><span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">)</span> <span class="k">function </span><span class="n">divide_tn</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">mul</span><span class="p">)</span>
<a name="ln-105"></a>
<a name="ln-106"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-107"></a>	<span class="k">class</span><span class="p">(</span><span class="o">*</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">mul</span>
<a name="ln-108"></a>
<a name="ln-109"></a>	<span class="n">divide_tn</span><span class="p">%</span><span class="n">grp</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">grp</span>
<a name="ln-110"></a>
<a name="ln-111"></a>	<span class="k">select type</span><span class="p">(</span><span class="n">mul</span><span class="p">)</span>
<a name="ln-112"></a>	<span class="k">type is</span><span class="p">(</span><span class="kt">real</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<a name="ln-113"></a>		<span class="n">divide_tn</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="o">/</span><span class="n">mul</span>
<a name="ln-114"></a>	<span class="k">type is</span><span class="p">(</span><span class="kt">real</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<a name="ln-115"></a>		<span class="n">divide_tn</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="o">/</span><span class="n">mul</span>
<a name="ln-116"></a>	<span class="k">type is</span><span class="p">(</span><span class="kt">complex</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<a name="ln-117"></a>		<span class="n">divide_tn</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="o">/</span><span class="n">mul</span>
<a name="ln-118"></a>	<span class="k">type is</span><span class="p">(</span><span class="kt">complex</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<a name="ln-119"></a>		<span class="n">divide_tn</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="o">/</span><span class="n">mul</span>
<a name="ln-120"></a>	<span class="k">end select</span>
<a name="ln-121"></a>
<a name="ln-122"></a><span class="k">end function</span>
<a name="ln-123"></a>
<a name="ln-124"></a><span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">)</span> <span class="k">function </span><span class="n">conjugate_tn</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
<a name="ln-125"></a>
<a name="ln-126"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-127"></a>
<a name="ln-128"></a>	<span class="n">conjugate_tn</span><span class="p">%</span><span class="n">grp</span><span class="o">=</span><span class="n">T</span><span class="p">%</span><span class="n">grp</span>
<a name="ln-129"></a>	<span class="n">conjugate_tn</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="p">.</span><span class="n">con</span><span class="p">.</span> <span class="n">T</span><span class="p">%</span><span class="n">tensor</span>	
<a name="ln-130"></a>
<a name="ln-131"></a><span class="k">end function</span>
<a name="ln-132"></a>
<a name="ln-133"></a><span class="k">subroutine </span><span class="n">assignmentTN</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span><span class="n">T2</span><span class="p">)</span>
<a name="ln-134"></a>
<a name="ln-135"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">T2</span>
<a name="ln-136"></a>	<span class="k">class</span><span class="p">(</span><span class="o">*</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T1</span>
<a name="ln-137"></a>
<a name="ln-138"></a>	<span class="k">select type</span><span class="p">(</span><span class="n">T1</span><span class="p">)</span>
<a name="ln-139"></a>	<span class="k">type is</span><span class="p">(</span><span class="kt">real</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<a name="ln-140"></a>		<span class="k">if</span><span class="p">(</span><span class="n">T2</span><span class="p">%</span><span class="n">gettotaldata</span><span class="p">()</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="k">then</span>
<a name="ln-141"></a><span class="k">			</span><span class="n">T1</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">si</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<a name="ln-142"></a>		<span class="k">else</span>
<a name="ln-143"></a><span class="k">			call </span><span class="n">wc_error_stop</span><span class="p">(</span><span class="s1">&#39;assignmentTN&#39;</span><span class="p">,</span><span class="s1">&#39;Tensor should be 1D to assign to a real4 number&#39;</span><span class="p">)</span>
<a name="ln-144"></a>		<span class="k">end if</span>
<a name="ln-145"></a><span class="k">	type is</span><span class="p">(</span><span class="kt">real</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<a name="ln-146"></a>		<span class="k">if</span><span class="p">(</span><span class="n">T2</span><span class="p">%</span><span class="n">gettotaldata</span><span class="p">()</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="k">then</span>
<a name="ln-147"></a><span class="k">			</span><span class="n">T1</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">di</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<a name="ln-148"></a>		<span class="k">else</span>
<a name="ln-149"></a><span class="k">			call </span><span class="n">wc_error_stop</span><span class="p">(</span><span class="s1">&#39;assignmentTN&#39;</span><span class="p">,</span><span class="s1">&#39;Tensor should be 1D to assign to a real8 number&#39;</span><span class="p">)</span>
<a name="ln-150"></a>		<span class="k">end if</span>
<a name="ln-151"></a><span class="k">	type is</span><span class="p">(</span><span class="kt">complex</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<a name="ln-152"></a>		<span class="k">if</span><span class="p">(</span><span class="n">T2</span><span class="p">%</span><span class="n">gettotaldata</span><span class="p">()</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="k">then</span>
<a name="ln-153"></a><span class="k">			</span><span class="n">T1</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">ci</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<a name="ln-154"></a>		<span class="k">else</span>
<a name="ln-155"></a><span class="k">			call </span><span class="n">wc_error_stop</span><span class="p">(</span><span class="s1">&#39;assignmentTN&#39;</span><span class="p">,</span><span class="s1">&#39;Tensor should be 1D to assign to a com4 number&#39;</span><span class="p">)</span>
<a name="ln-156"></a>		<span class="k">end if</span>
<a name="ln-157"></a><span class="k">	type is</span><span class="p">(</span><span class="kt">complex</span><span class="p">(</span><span class="mi">8</span><span class="p">))</span>
<a name="ln-158"></a>		<span class="k">if</span><span class="p">(</span><span class="n">T2</span><span class="p">%</span><span class="n">gettotaldata</span><span class="p">()</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="k">then</span>
<a name="ln-159"></a><span class="k">			</span><span class="n">T1</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">zi</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<a name="ln-160"></a>		<span class="k">else</span>
<a name="ln-161"></a><span class="k">			call </span><span class="n">wc_error_stop</span><span class="p">(</span><span class="s1">&#39;assignmentTN&#39;</span><span class="p">,</span><span class="s1">&#39;Tensor should be 1D to assign to a com8 number&#39;</span><span class="p">)</span>
<a name="ln-162"></a>		<span class="k">end if</span>
<a name="ln-163"></a><span class="k">	type is</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
<a name="ln-164"></a>		<span class="n">T1</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">tensor</span>
<a name="ln-165"></a>	<span class="k">type is</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">)</span>
<a name="ln-166"></a>		<span class="n">T1</span><span class="p">%</span><span class="n">grp</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">grp</span>
<a name="ln-167"></a>		<span class="n">T1</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">tensor</span>
<a name="ln-168"></a>	<span class="k">end select</span>
<a name="ln-169"></a>
<a name="ln-170"></a><span class="k">end subroutine</span>
<a name="ln-171"></a>
<a name="ln-172"></a><span class="k">subroutine </span><span class="n">assignmentDTN</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span><span class="n">T2</span><span class="p">)</span>
<a name="ln-173"></a>
<a name="ln-174"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">T2</span>
<a name="ln-175"></a>	<span class="kt">real</span><span class="p">(</span><span class="mi">8</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T1</span>
<a name="ln-176"></a>
<a name="ln-177"></a>	<span class="k">if</span><span class="p">(</span><span class="n">T2</span><span class="p">%</span><span class="n">gettotaldata</span><span class="p">()</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="k">then</span>
<a name="ln-178"></a><span class="k">		</span><span class="n">T1</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">di</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<a name="ln-179"></a>	<span class="k">else</span>
<a name="ln-180"></a><span class="k">		call </span><span class="n">wc_error_stop</span><span class="p">(</span><span class="s1">&#39;assignmentTN&#39;</span><span class="p">,</span><span class="s1">&#39;Tensor should be 1D to assign to a real8 number&#39;</span><span class="p">)</span>
<a name="ln-181"></a>	<span class="k">end if</span>
<a name="ln-182"></a>
<a name="ln-183"></a><span class="k">end subroutine</span>
<a name="ln-184"></a>
<a name="ln-185"></a><span class="k">subroutine </span><span class="n">assignmentZTN</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span><span class="n">T2</span><span class="p">)</span>
<a name="ln-186"></a>
<a name="ln-187"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">T2</span>
<a name="ln-188"></a>	<span class="kt">complex</span><span class="p">(</span><span class="mi">8</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T1</span>
<a name="ln-189"></a>
<a name="ln-190"></a>	<span class="k">if</span><span class="p">(</span><span class="n">T2</span><span class="p">%</span><span class="n">gettotaldata</span><span class="p">()</span><span class="o">==</span><span class="mi">1</span><span class="p">)</span> <span class="k">then</span>
<a name="ln-191"></a><span class="k">		</span><span class="n">T1</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">zi</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<a name="ln-192"></a>	<span class="k">else</span>
<a name="ln-193"></a><span class="k">		call </span><span class="n">wc_error_stop</span><span class="p">(</span><span class="s1">&#39;assignmentTN&#39;</span><span class="p">,</span><span class="s1">&#39;Tensor should be 1D to assign to a com8 number&#39;</span><span class="p">)</span>
<a name="ln-194"></a>	<span class="k">end if</span>
<a name="ln-195"></a>
<a name="ln-196"></a><span class="k">end subroutine</span>
<a name="ln-197"></a>
<a name="ln-198"></a><span class="k">subroutine </span><span class="n">assignmentTTN</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span><span class="n">T2</span><span class="p">)</span>
<a name="ln-199"></a>
<a name="ln-200"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">T2</span>
<a name="ln-201"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T1</span>
<a name="ln-202"></a>
<a name="ln-203"></a>	<span class="n">T1</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">tensor</span>
<a name="ln-204"></a>
<a name="ln-205"></a><span class="k">end subroutine</span>
<a name="ln-206"></a>
<a name="ln-207"></a><span class="k">subroutine </span><span class="n">assignmentTNTN</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span><span class="n">T2</span><span class="p">)</span>
<a name="ln-208"></a>
<a name="ln-209"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">T2</span>
<a name="ln-210"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T1</span>
<a name="ln-211"></a>
<a name="ln-212"></a>	<span class="n">T1</span><span class="p">%</span><span class="n">grp</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">grp</span>
<a name="ln-213"></a>	<span class="n">T1</span><span class="p">%</span><span class="n">tensor</span><span class="o">=</span><span class="n">T2</span><span class="p">%</span><span class="n">tensor</span>
<a name="ln-214"></a>
<a name="ln-215"></a><span class="k">end subroutine</span>
<a name="ln-216"></a>
<a name="ln-217"></a><span class="k">subroutine </span><span class="n">belong</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">L</span><span class="p">)</span>
<a name="ln-218"></a>
<a name="ln-219"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-220"></a>	<span class="k">class</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">target</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span> <span class="kd">::</span><span class="n">L</span>
<a name="ln-221"></a>
<a name="ln-222"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">belong</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
<a name="ln-223"></a>
<a name="ln-224"></a><span class="k">end subroutine</span>
<a name="ln-225"></a>
<a name="ln-226"></a><span class="k">subroutine </span><span class="n">empty</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
<a name="ln-227"></a>
<a name="ln-228"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-229"></a>
<a name="ln-230"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">empty</span>
<a name="ln-231"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="p">%</span><span class="n">empty</span><span class="p">()</span>
<a name="ln-232"></a>
<a name="ln-233"></a><span class="k">end subroutine</span>
<a name="ln-234"></a>
<a name="ln-235"></a><span class="k">subroutine </span><span class="n">draw</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">tnname</span><span class="p">,</span><span class="n">label_bond</span><span class="p">,</span><span class="n">fixed</span><span class="p">,</span><span class="n">check_tag</span><span class="p">)</span>
<a name="ln-236"></a>
<a name="ln-237"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-238"></a>	<span class="kt">character</span><span class="p">(</span><span class="nb">len</span><span class="o">=*</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">tnname</span>
<a name="ln-239"></a>	<span class="kt">logical</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">),</span><span class="k">optional</span><span class="kd">::</span><span class="n">label_bond</span><span class="p">,</span><span class="n">fixed</span><span class="p">,</span><span class="n">check_tag</span>
<a name="ln-240"></a>
<a name="ln-241"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="n">tnname</span><span class="p">,</span><span class="n">tnname</span><span class="p">,</span><span class="n">label_bond</span><span class="p">,</span><span class="n">fixed</span><span class="p">,</span><span class="n">check_tag</span><span class="p">)</span>
<a name="ln-242"></a>
<a name="ln-243"></a><span class="k">end subroutine</span>
<a name="ln-244"></a>
<a name="ln-245"></a><span class="k">subroutine </span><span class="n">get_info</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
<a name="ln-246"></a>
<a name="ln-247"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-248"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">L1</span><span class="p">,</span><span class="n">L2</span>
<a name="ln-249"></a>
<a name="ln-250"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">get_info</span>
<a name="ln-251"></a>	<span class="k">call </span><span class="n">write_message</span><span class="p">(</span><span class="s1">&#39;The dim of tensor is :&#39;</span><span class="p">)</span>
<a name="ln-252"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">diminfo</span><span class="p">()</span>
<a name="ln-253"></a>	<span class="k">call </span><span class="n">write_message</span><span class="p">(</span><span class="s1">&#39;The program has been paused. Please press any key to continue&#39;</span><span class="p">)</span>
<a name="ln-254"></a>	<span class="k">read</span><span class="p">(</span><span class="o">*</span><span class="p">,</span><span class="o">*</span><span class="p">)</span>
<a name="ln-255"></a>
<a name="ln-256"></a><span class="k">end subroutine</span>
<a name="ln-257"></a>
<a name="ln-258"></a><span class="k">subroutine </span><span class="n">take</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>	<span class="c">!if already includes or pos have no tn, don&#39;t do anything</span>
<a name="ln-259"></a>
<a name="ln-260"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-261"></a>	<span class="kt">integer</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-262"></a>
<a name="ln-263"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">take</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>
<a name="ln-264"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_take&#39;</span><span class="p">)</span>
<a name="ln-265"></a>
<a name="ln-266"></a><span class="k">end subroutine</span>
<a name="ln-267"></a>
<a name="ln-268"></a><span class="k">subroutine </span><span class="n">absorb</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>	<span class="c">!if already includes or pos have no tn, don&#39;t do anything</span>
<a name="ln-269"></a>
<a name="ln-270"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-271"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span><span class="kd">::</span><span class="n">tt</span>
<a name="ln-272"></a>	<span class="kt">integer</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-273"></a>		
<a name="ln-274"></a>	<span class="k">call </span><span class="n">lat_absorb_tensor</span><span class="p">(</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="p">,</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="p">,</span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>
<a name="ln-275"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb&#39;</span><span class="p">)</span>
<a name="ln-276"></a>
<a name="ln-277"></a><span class="k">end subroutine</span>
<a name="ln-278"></a>
<a name="ln-279"></a><span class="k">subroutine </span><span class="n">absorb_just_env</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>	<span class="c">!if already includes or pos have no tn, don&#39;t do anything</span>
<a name="ln-280"></a>
<a name="ln-281"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-282"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span><span class="kd">::</span><span class="n">tt</span>
<a name="ln-283"></a>	<span class="kt">integer</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-284"></a>		
<a name="ln-285"></a>	<span class="k">call </span><span class="n">lat_absorb_env</span><span class="p">(</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="p">,</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="p">,</span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>
<a name="ln-286"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb&#39;</span><span class="p">)</span>
<a name="ln-287"></a>
<a name="ln-288"></a><span class="k">end subroutine</span>
<a name="ln-289"></a>
<a name="ln-290"></a><span class="k">subroutine </span><span class="n">absorb_with_env</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>	<span class="c">!if already includes or pos have no tn, don&#39;t do anything</span>
<a name="ln-291"></a>
<a name="ln-292"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-293"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span><span class="kd">::</span><span class="n">tt</span>
<a name="ln-294"></a>	<span class="kt">integer</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-295"></a>		
<a name="ln-296"></a>	<span class="k">call </span><span class="n">absorb_just_env</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>
<a name="ln-297"></a>	<span class="k">call </span><span class="n">absorb</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>
<a name="ln-298"></a>
<a name="ln-299"></a><span class="k">end subroutine</span>
<a name="ln-300"></a>
<a name="ln-301"></a><span class="k">subroutine </span><span class="n">absorb_rt</span><span class="p">(</span><span class="n">Tout</span><span class="p">,</span><span class="n">Tin</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>	<span class="c">!if already includes or pos have no tn, don&#39;t do anything</span>
<a name="ln-302"></a>
<a name="ln-303"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">Tout</span><span class="p">,</span><span class="n">Tin</span>
<a name="ln-304"></a>	<span class="kt">integer</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-305"></a>
<a name="ln-306"></a>	<span class="n">Tout</span><span class="p">%</span><span class="n">grp</span><span class="o">=</span><span class="n">Tin</span><span class="p">%</span><span class="n">grp</span>
<a name="ln-307"></a>	<span class="k">call </span><span class="n">lat_absorb_tensor</span><span class="p">(</span><span class="n">Tout</span><span class="p">%</span><span class="n">tensor</span><span class="p">,</span><span class="n">Tin</span><span class="p">%</span><span class="n">tensor</span><span class="p">,</span><span class="n">Tout</span><span class="p">%</span><span class="n">grp</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>
<a name="ln-308"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">Tout</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb&#39;</span><span class="p">)</span>
<a name="ln-309"></a>
<a name="ln-310"></a><span class="k">end subroutine</span>
<a name="ln-311"></a>
<a name="ln-312"></a><span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">)</span> <span class="k">function </span><span class="n">contract_TNTN</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span><span class="n">T2</span><span class="p">)</span> <span class="k">result</span><span class="p">(</span><span class="n">Res</span><span class="p">)</span>
<a name="ln-313"></a>	
<a name="ln-314"></a>	<span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T1</span><span class="p">,</span><span class="n">T2</span>
<a name="ln-315"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">num</span>
<a name="ln-316"></a>
<a name="ln-317"></a>	<span class="n">Res</span><span class="p">%</span><span class="n">grp</span><span class="o">=</span><span class="n">T1</span><span class="p">%</span><span class="n">grp</span>
<a name="ln-318"></a>	<span class="k">call </span><span class="n">lat_contract_type</span><span class="p">(</span><span class="n">Res</span><span class="p">%</span><span class="n">Tensor</span><span class="p">,</span><span class="n">T1</span><span class="p">%</span><span class="n">Tensor</span><span class="p">,</span><span class="n">T2</span><span class="p">%</span><span class="n">Tensor</span><span class="p">,</span><span class="n">Res</span><span class="p">%</span><span class="n">grp</span><span class="p">,</span><span class="n">T2</span><span class="p">%</span><span class="n">grp</span><span class="p">)</span>
<a name="ln-319"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">Res</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_contract&#39;</span><span class="p">)</span>
<a name="ln-320"></a>
<a name="ln-321"></a><span class="k">end function</span>
<a name="ln-322"></a>
<a name="ln-323"></a><span class="k">subroutine </span><span class="n">absorb_all1</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span><span class="n">T2</span><span class="p">,</span><span class="n">abp_</span><span class="p">)</span>
<a name="ln-324"></a>
<a name="ln-325"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T1</span>
<a name="ln-326"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T2</span>
<a name="ln-327"></a>	<span class="k">type</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">pointer</span><span class="kd">::</span><span class="n">plat</span>
<a name="ln-328"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">),</span><span class="k">optional</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">abp_</span>
<a name="ln-329"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="kd">::</span><span class="n">abp</span>
<a name="ln-330"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">i</span><span class="p">,</span><span class="n">path_pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-331"></a>
<a name="ln-332"></a>	<span class="k">call </span><span class="n">T1</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">point_lat</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-333"></a>
<a name="ln-334"></a>	<span class="k">if</span><span class="p">(</span><span class="nb">present</span><span class="p">(</span><span class="n">abp_</span><span class="p">))</span><span class="k">then</span>
<a name="ln-335"></a><span class="k">		</span><span class="n">abp</span><span class="o">=</span><span class="n">abp_</span>
<a name="ln-336"></a>	<span class="k">else</span>
<a name="ln-337"></a><span class="k">		call </span><span class="n">abp</span><span class="p">%</span><span class="n">belong</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-338"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39;lu&#39;</span><span class="p">,</span><span class="n">T2</span><span class="p">%</span><span class="n">grp</span><span class="p">)</span>
<a name="ln-339"></a>	<span class="k">end if</span>
<a name="ln-340"></a>
<a name="ln-341"></a><span class="k">	if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T1</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_T1_before&#39;</span><span class="p">)</span>
<a name="ln-342"></a>
<a name="ln-343"></a>	<span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">abp</span><span class="p">%</span><span class="n">get_num</span><span class="p">()</span>
<a name="ln-344"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">iterate</span><span class="p">(</span><span class="n">path_pos</span><span class="p">,(</span><span class="n">i</span><span class="o">==</span><span class="mi">1</span><span class="p">))</span>
<a name="ln-345"></a>		<span class="k">call </span><span class="n">T1</span><span class="p">%</span><span class="n">absorb</span><span class="p">(</span><span class="n">path_pos</span><span class="p">)</span>
<a name="ln-346"></a>	<span class="k">end do</span>
<a name="ln-347"></a>
<a name="ln-348"></a><span class="k">	if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T1</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_T1_after&#39;</span><span class="p">)</span>
<a name="ln-349"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T2</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_T2&#39;</span><span class="p">)</span>
<a name="ln-350"></a>
<a name="ln-351"></a>	<span class="k">call </span><span class="n">lat_contract_type</span><span class="p">(</span><span class="n">T1</span><span class="p">%</span><span class="n">Tensor</span><span class="p">,</span><span class="n">T1</span><span class="p">%</span><span class="n">Tensor</span><span class="p">,</span><span class="n">T2</span><span class="p">%</span><span class="n">Tensor</span><span class="p">,</span><span class="n">T1</span><span class="p">%</span><span class="n">grp</span><span class="p">,</span><span class="n">T2</span><span class="p">%</span><span class="n">grp</span><span class="p">)</span>
<a name="ln-352"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T1</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_result&#39;</span><span class="p">)</span>
<a name="ln-353"></a>
<a name="ln-354"></a><span class="k">end subroutine</span>
<a name="ln-355"></a>
<a name="ln-356"></a><span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">)</span> <span class="k">function </span><span class="n">absorb_all1_rt</span><span class="p">(</span><span class="n">T1</span><span class="p">,</span><span class="n">T2</span><span class="p">,</span><span class="n">abp</span><span class="p">)</span><span class="k">result</span><span class="p">(</span><span class="n">Res</span><span class="p">)</span>
<a name="ln-357"></a>
<a name="ln-358"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T1</span>
<a name="ln-359"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T2</span>
<a name="ln-360"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">),</span><span class="k">optional</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">abp</span>
<a name="ln-361"></a>
<a name="ln-362"></a>	<span class="n">Res</span><span class="o">=</span><span class="n">T1</span>
<a name="ln-363"></a>	<span class="k">call </span><span class="n">Res</span><span class="p">%</span><span class="n">absorb_all1</span><span class="p">(</span><span class="n">T2</span><span class="p">,</span><span class="n">abp</span><span class="p">)</span>
<a name="ln-364"></a>
<a name="ln-365"></a><span class="k">end function</span>
<a name="ln-366"></a>
<a name="ln-367"></a><span class="k">subroutine </span><span class="n">absorb_all0</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">abp_</span><span class="p">)</span>
<a name="ln-368"></a>
<a name="ln-369"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-370"></a>	<span class="k">type</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">pointer</span><span class="kd">::</span><span class="n">plat</span>
<a name="ln-371"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">),</span><span class="k">optional</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">abp_</span>
<a name="ln-372"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="kd">::</span><span class="n">abp</span>
<a name="ln-373"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">i</span><span class="p">,</span><span class="n">path_pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-374"></a>
<a name="ln-375"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_T&#39;</span><span class="p">)</span>
<a name="ln-376"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">point_lat</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-377"></a>
<a name="ln-378"></a>	<span class="k">if</span><span class="p">(</span><span class="nb">present</span><span class="p">(</span><span class="n">abp_</span><span class="p">))</span><span class="k">then</span>
<a name="ln-379"></a><span class="k">		</span><span class="n">abp</span><span class="o">=</span><span class="n">abp_</span>
<a name="ln-380"></a>	<span class="k">else</span>
<a name="ln-381"></a><span class="k">		call </span><span class="n">abp</span><span class="p">%</span><span class="n">belong</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-382"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39;lu&#39;</span><span class="p">)</span>
<a name="ln-383"></a>	<span class="k">end if</span>
<a name="ln-384"></a>
<a name="ln-385"></a><span class="k">	do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">abp</span><span class="p">%</span><span class="n">get_num</span><span class="p">()</span>
<a name="ln-386"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">iterate</span><span class="p">(</span><span class="n">path_pos</span><span class="p">,(</span><span class="n">i</span><span class="o">==</span><span class="mi">1</span><span class="p">))</span>
<a name="ln-387"></a>		<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">absorb</span><span class="p">(</span><span class="n">path_pos</span><span class="p">)</span>
<a name="ln-388"></a>	<span class="k">end do</span>
<a name="ln-389"></a>
<a name="ln-390"></a><span class="k">	if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_result&#39;</span><span class="p">)</span>
<a name="ln-391"></a>
<a name="ln-392"></a><span class="k">end subroutine</span>
<a name="ln-393"></a>
<a name="ln-394"></a><span class="k">type</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">)</span> <span class="k">function </span><span class="n">absorb_all0_rt</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">abp</span><span class="p">)</span><span class="k">result</span><span class="p">(</span><span class="n">Res</span><span class="p">)</span>
<a name="ln-395"></a>
<a name="ln-396"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-397"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">),</span><span class="k">optional</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">abp</span>
<a name="ln-398"></a>	
<a name="ln-399"></a>	<span class="n">Res</span><span class="o">=</span><span class="n">T</span>
<a name="ln-400"></a>	<span class="k">call </span><span class="n">Res</span><span class="p">%</span><span class="n">absorb_all0</span><span class="p">(</span><span class="n">abp</span><span class="p">)</span>
<a name="ln-401"></a>
<a name="ln-402"></a><span class="k">end function</span>
<a name="ln-403"></a>
<a name="ln-404"></a><span class="k">subroutine </span><span class="n">absorb0_except_pos</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">pos</span><span class="p">,</span><span class="n">abp_</span><span class="p">)</span>
<a name="ln-405"></a>
<a name="ln-406"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-407"></a>	<span class="k">type</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">pointer</span><span class="kd">::</span><span class="n">plat</span>
<a name="ln-408"></a>	<span class="kt">integer</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-409"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">),</span><span class="k">optional</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">abp_</span>
<a name="ln-410"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">i</span><span class="p">,</span><span class="n">path_pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-411"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="kd">::</span><span class="n">abp</span>
<a name="ln-412"></a>	<span class="k">type</span><span class="p">(</span><span class="n">group</span><span class="p">)</span><span class="kd">::</span><span class="n">avoid_grp</span>
<a name="ln-413"></a>
<a name="ln-414"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">point_lat</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-415"></a>
<a name="ln-416"></a>	<span class="k">if</span><span class="p">(</span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">check_contain</span><span class="p">(</span><span class="n">pos</span><span class="p">))</span> <span class="k">then</span>
<a name="ln-417"></a><span class="k">		call </span><span class="n">wc_error_stop</span><span class="p">(</span><span class="s1">&#39;tn_tensor.absorb_except&#39;</span><span class="p">,</span><span class="s1">&#39;site at pos already contained in the group1&#39;</span><span class="p">)</span>
<a name="ln-418"></a>	<span class="k">end if</span>
<a name="ln-419"></a>
<a name="ln-420"></a><span class="k">	if</span><span class="p">(</span><span class="nb">present</span><span class="p">(</span><span class="n">abp_</span><span class="p">))</span><span class="k">then</span>
<a name="ln-421"></a><span class="k">		</span><span class="n">abp</span><span class="o">=</span><span class="n">abp_</span>
<a name="ln-422"></a>	<span class="k">else</span>
<a name="ln-423"></a><span class="k">		call </span><span class="n">abp</span><span class="p">%</span><span class="n">belong</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-424"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39;lu&#39;</span><span class="p">)</span>
<a name="ln-425"></a>	<span class="k">end if</span>
<a name="ln-426"></a>	<span class="c">!call abp%draw(&#39;absorb_except&#39;,check_tag=.false.)</span>
<a name="ln-427"></a>
<a name="ln-428"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_except_T&#39;</span><span class="p">)</span>
<a name="ln-429"></a>
<a name="ln-430"></a>	<span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">abp</span><span class="p">%</span><span class="n">get_num</span><span class="p">()</span>
<a name="ln-431"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">iterate</span><span class="p">(</span><span class="n">path_pos</span><span class="p">,(</span><span class="n">i</span><span class="o">==</span><span class="mi">1</span><span class="p">))</span>
<a name="ln-432"></a>		<span class="c">!write(*,*)path_pos</span>
<a name="ln-433"></a>		<span class="k">if</span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span> <span class="k">all</span><span class="p">(</span><span class="n">path_pos</span><span class="o">==</span><span class="n">pos</span><span class="p">))</span><span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">absorb</span><span class="p">(</span><span class="n">path_pos</span><span class="p">)</span>
<a name="ln-434"></a>		<span class="c">!call T%draw(&#39;tn_absorb_except_test&#39;,check_tag=.false.)</span>
<a name="ln-435"></a>	<span class="k">end do</span>
<a name="ln-436"></a>
<a name="ln-437"></a><span class="k">	if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_except_result&#39;</span><span class="p">)</span>
<a name="ln-438"></a>
<a name="ln-439"></a><span class="k">end subroutine</span>
<a name="ln-440"></a>
<a name="ln-441"></a><span class="k">subroutine </span><span class="n">take_except_pos</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">pos</span><span class="p">)</span>
<a name="ln-442"></a>
<a name="ln-443"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-444"></a>	<span class="k">type</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">pointer</span><span class="kd">::</span><span class="n">plat</span>
<a name="ln-445"></a>	<span class="kt">integer</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-446"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">i</span><span class="p">,</span><span class="n">path_pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-447"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="kd">::</span><span class="n">abp</span>
<a name="ln-448"></a>
<a name="ln-449"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">point_lat</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-450"></a>	<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">belong</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-451"></a>	<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39;lu&#39;</span><span class="p">)</span>
<a name="ln-452"></a>
<a name="ln-453"></a>	<span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">abp</span><span class="p">%</span><span class="n">get_num</span><span class="p">()</span>
<a name="ln-454"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">iterate</span><span class="p">(</span><span class="n">path_pos</span><span class="p">,(</span><span class="n">i</span><span class="o">==</span><span class="mi">1</span><span class="p">))</span>
<a name="ln-455"></a>		<span class="c">!write(*,*)path_pos</span>
<a name="ln-456"></a>		<span class="k">if</span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span> <span class="k">all</span><span class="p">(</span><span class="n">path_pos</span><span class="o">==</span><span class="n">pos</span><span class="p">))</span><span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">take</span><span class="p">(</span><span class="n">path_pos</span><span class="p">)</span>
<a name="ln-457"></a>		<span class="c">!call T%draw(&#39;tn_absorb_except_test&#39;,check_tag=.false.)</span>
<a name="ln-458"></a>	<span class="k">end do</span>
<a name="ln-459"></a>
<a name="ln-460"></a><span class="k">end subroutine</span>
<a name="ln-461"></a>
<a name="ln-462"></a><span class="k">subroutine </span><span class="n">take_except_name</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">name</span><span class="p">)</span>
<a name="ln-463"></a>
<a name="ln-464"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-465"></a>	<span class="k">type</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">pointer</span><span class="kd">::</span><span class="n">plat</span>
<a name="ln-466"></a>	<span class="kt">character</span><span class="p">(</span><span class="nb">len</span><span class="o">=*</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">name</span>
<a name="ln-467"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-468"></a>
<a name="ln-469"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">point_lat</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-470"></a>	<span class="n">pos</span><span class="o">=</span><span class="n">plat</span><span class="p">%</span><span class="n">get_pos</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<a name="ln-471"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">take_except_pos</span><span class="p">(</span><span class="n">pos</span><span class="p">)</span>
<a name="ln-472"></a>
<a name="ln-473"></a><span class="k">end subroutine</span>
<a name="ln-474"></a>
<a name="ln-475"></a><span class="k">subroutine </span><span class="n">take_except_path</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">pat</span><span class="p">)</span>
<a name="ln-476"></a>
<a name="ln-477"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-478"></a>	<span class="k">type</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">pointer</span><span class="kd">::</span><span class="n">plat</span>
<a name="ln-479"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">pat</span>
<a name="ln-480"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">i</span><span class="p">,</span><span class="n">path_pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-481"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="kd">::</span><span class="n">abp</span>
<a name="ln-482"></a>
<a name="ln-483"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">point_lat</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-484"></a>	<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">belong</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-485"></a>	<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39;lu&#39;</span><span class="p">)</span>
<a name="ln-486"></a>
<a name="ln-487"></a>	<span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">abp</span><span class="p">%</span><span class="n">get_num</span><span class="p">()</span>
<a name="ln-488"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">iterate</span><span class="p">(</span><span class="n">path_pos</span><span class="p">,(</span><span class="n">i</span><span class="o">==</span><span class="mi">1</span><span class="p">))</span>
<a name="ln-489"></a>		<span class="c">!write(*,*)path_pos</span>
<a name="ln-490"></a>		<span class="k">if</span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span> <span class="n">pat</span><span class="p">%</span><span class="n">check_contain</span><span class="p">(</span><span class="n">path_pos</span><span class="p">))</span><span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">take</span><span class="p">(</span><span class="n">path_pos</span><span class="p">)</span>
<a name="ln-491"></a>		<span class="c">!call T%draw(&#39;tn_absorb_except_test&#39;,check_tag=.false.)</span>
<a name="ln-492"></a>	<span class="k">end do</span>
<a name="ln-493"></a>
<a name="ln-494"></a><span class="k">end subroutine</span>
<a name="ln-495"></a>
<a name="ln-496"></a><span class="k">subroutine </span><span class="n">take_except_group</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">grp</span><span class="p">)</span>
<a name="ln-497"></a>
<a name="ln-498"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-499"></a>	<span class="k">type</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">pointer</span><span class="kd">::</span><span class="n">plat</span>
<a name="ln-500"></a>	<span class="k">type</span><span class="p">(</span><span class="n">group</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">grp</span>
<a name="ln-501"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">i</span><span class="p">,</span><span class="n">path_pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-502"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="kd">::</span><span class="n">abp</span>
<a name="ln-503"></a>
<a name="ln-504"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">point_lat</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-505"></a>	<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">belong</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-506"></a>	<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39;lu&#39;</span><span class="p">)</span>
<a name="ln-507"></a>
<a name="ln-508"></a>	<span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">abp</span><span class="p">%</span><span class="n">get_num</span><span class="p">()</span>
<a name="ln-509"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">iterate</span><span class="p">(</span><span class="n">path_pos</span><span class="p">,(</span><span class="n">i</span><span class="o">==</span><span class="mi">1</span><span class="p">))</span>
<a name="ln-510"></a>		<span class="c">!write(*,*)path_pos</span>
<a name="ln-511"></a>		<span class="k">if</span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span> <span class="n">grp</span><span class="p">%</span><span class="n">check_contain</span><span class="p">(</span><span class="n">path_pos</span><span class="p">))</span><span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">take</span><span class="p">(</span><span class="n">path_pos</span><span class="p">)</span>
<a name="ln-512"></a>		<span class="c">!call T%draw(&#39;tn_absorb_except_test&#39;,check_tag=.false.)</span>
<a name="ln-513"></a>	<span class="k">end do</span>
<a name="ln-514"></a>
<a name="ln-515"></a><span class="k">end subroutine</span>
<a name="ln-516"></a><span class="k">subroutine </span><span class="n">absorb1_except_pos</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">T2</span><span class="p">,</span><span class="n">pos</span><span class="p">,</span><span class="n">abp_</span><span class="p">)</span>
<a name="ln-517"></a>
<a name="ln-518"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span><span class="p">,</span><span class="n">T2</span>
<a name="ln-519"></a>	<span class="k">type</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">pointer</span><span class="kd">::</span><span class="n">plat</span>
<a name="ln-520"></a>	<span class="kt">integer</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-521"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">),</span><span class="k">optional</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">abp_</span>
<a name="ln-522"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">i</span><span class="p">,</span><span class="n">path_pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-523"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">)</span><span class="kd">::</span><span class="n">abp</span>
<a name="ln-524"></a>
<a name="ln-525"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">point_lat</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-526"></a>
<a name="ln-527"></a>	<span class="k">if</span><span class="p">(</span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">check_contain</span><span class="p">(</span><span class="n">pos</span><span class="p">))</span> <span class="k">then</span>
<a name="ln-528"></a><span class="k">		call </span><span class="n">wc_error_stop</span><span class="p">(</span><span class="s1">&#39;tn_tensor.absorb_except&#39;</span><span class="p">,</span><span class="s1">&#39;site at pos already contained in the group&#39;</span><span class="p">)</span>
<a name="ln-529"></a>	<span class="k">end if</span>
<a name="ln-530"></a>
<a name="ln-531"></a><span class="k">	if</span><span class="p">(</span><span class="n">T2</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">check_contain</span><span class="p">(</span><span class="n">pos</span><span class="p">))</span> <span class="k">then</span>
<a name="ln-532"></a><span class="k">		call </span><span class="n">wc_error_stop</span><span class="p">(</span><span class="s1">&#39;tn_tensor.absorb_except&#39;</span><span class="p">,</span><span class="s1">&#39;site at pos already contained in the group2&#39;</span><span class="p">)</span>
<a name="ln-533"></a>	<span class="k">end if</span>
<a name="ln-534"></a>
<a name="ln-535"></a><span class="k">	if</span><span class="p">(</span><span class="nb">present</span><span class="p">(</span><span class="n">abp_</span><span class="p">))</span><span class="k">then</span>
<a name="ln-536"></a><span class="k">		</span><span class="n">abp</span><span class="o">=</span><span class="n">abp_</span>
<a name="ln-537"></a>	<span class="k">else</span>
<a name="ln-538"></a><span class="k">		call </span><span class="n">abp</span><span class="p">%</span><span class="n">belong</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-539"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">generate</span><span class="p">(</span><span class="s1">&#39;lu&#39;</span><span class="p">)</span>
<a name="ln-540"></a>	<span class="k">end if</span>
<a name="ln-541"></a>	<span class="c">!call abp%draw(&#39;absorb_except&#39;,check_tag=.false.)</span>
<a name="ln-542"></a>
<a name="ln-543"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_except_T&#39;</span><span class="p">)</span>
<a name="ln-544"></a>
<a name="ln-545"></a>	<span class="k">do </span><span class="n">i</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">abp</span><span class="p">%</span><span class="n">get_num</span><span class="p">()</span>
<a name="ln-546"></a>		<span class="k">call </span><span class="n">abp</span><span class="p">%</span><span class="n">iterate</span><span class="p">(</span><span class="n">path_pos</span><span class="p">,(</span><span class="n">i</span><span class="o">==</span><span class="mi">1</span><span class="p">))</span>
<a name="ln-547"></a>		<span class="c">!write(*,*)path_pos</span>
<a name="ln-548"></a>		<span class="k">if</span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span> <span class="p">(</span><span class="k">all</span><span class="p">(</span><span class="n">path_pos</span><span class="o">==</span><span class="n">pos</span><span class="p">)</span> <span class="p">.</span><span class="nb">or</span><span class="p">.</span> <span class="n">T2</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">check_contain</span><span class="p">(</span><span class="n">path_pos</span><span class="p">)))</span><span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">absorb</span><span class="p">(</span><span class="n">path_pos</span><span class="p">)</span>
<a name="ln-549"></a>		<span class="c">!call T%draw(&#39;tn_absorb_except_test&#39;,check_tag=.false.)</span>
<a name="ln-550"></a>	<span class="k">end do</span>
<a name="ln-551"></a>
<a name="ln-552"></a><span class="k">	if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_except_T_after&#39;</span><span class="p">)</span>
<a name="ln-553"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T2</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_except_T2&#39;</span><span class="p">)</span>
<a name="ln-554"></a>
<a name="ln-555"></a>	<span class="k">call </span><span class="n">lat_contract_type</span><span class="p">(</span><span class="n">T</span><span class="p">%</span><span class="n">Tensor</span><span class="p">,</span><span class="n">T</span><span class="p">%</span><span class="n">Tensor</span><span class="p">,</span><span class="n">T2</span><span class="p">%</span><span class="n">Tensor</span><span class="p">,</span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">,</span><span class="n">T2</span><span class="p">%</span><span class="n">grp</span><span class="p">)</span>
<a name="ln-556"></a>
<a name="ln-557"></a>	<span class="k">if</span><span class="p">(</span><span class="n">draw_mode</span><span class="p">)</span> <span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">draw</span><span class="p">(</span><span class="s1">&#39;tn_absorb_all_except_result&#39;</span><span class="p">)</span>
<a name="ln-558"></a>
<a name="ln-559"></a><span class="k">end subroutine</span>
<a name="ln-560"></a>
<a name="ln-561"></a><span class="k">subroutine </span><span class="n">absorb0_except_name</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">name</span><span class="p">,</span><span class="n">abp</span><span class="p">)</span>
<a name="ln-562"></a>
<a name="ln-563"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-564"></a>	<span class="k">type</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">pointer</span><span class="kd">::</span><span class="n">plat</span>
<a name="ln-565"></a>	<span class="kt">character</span><span class="p">(</span><span class="nb">len</span><span class="o">=*</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">name</span>
<a name="ln-566"></a>	<span class="k">type</span><span class="p">(</span><span class="n">path</span><span class="p">),</span><span class="k">optional</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">abp</span>
<a name="ln-567"></a>	<span class="kt">integer</span><span class="kd">::</span><span class="n">pos</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<a name="ln-568"></a>
<a name="ln-569"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">point_lat</span><span class="p">(</span><span class="n">plat</span><span class="p">)</span>
<a name="ln-570"></a>
<a name="ln-571"></a>	<span class="k">if</span><span class="p">(.</span><span class="nb">not</span><span class="p">.</span><span class="n">plat</span><span class="p">%</span><span class="n">check_exist</span><span class="p">(</span><span class="n">name</span><span class="p">))</span> <span class="k">then</span>
<a name="ln-572"></a><span class="k">		call </span><span class="n">wc_error_stop</span><span class="p">(</span><span class="s1">&#39;tn_tensor.absorb_except&#39;</span><span class="p">,</span><span class="s1">&#39;site at pos does not exist&#39;</span><span class="p">)</span>
<a name="ln-573"></a>	<span class="k">end if</span>
<a name="ln-574"></a>
<a name="ln-575"></a><span class="k">	</span><span class="n">pos</span><span class="o">=</span><span class="n">plat</span><span class="p">%</span><span class="n">get_pos</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
<a name="ln-576"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">absorb_except</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span><span class="n">abp</span><span class="p">)</span>
<a name="ln-577"></a>
<a name="ln-578"></a><span class="k">end subroutine</span>
<a name="ln-579"></a>
<a name="ln-580"></a><span class="k">subroutine </span><span class="n">invert_bond</span><span class="p">(</span><span class="n">T</span><span class="p">)</span>
<a name="ln-581"></a>
<a name="ln-582"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-583"></a>
<a name="ln-584"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">invert_bond</span><span class="p">(</span><span class="n">T</span><span class="p">%</span><span class="n">tensor</span><span class="p">)</span>
<a name="ln-585"></a>
<a name="ln-586"></a><span class="k">end subroutine</span>
<a name="ln-587"></a>
<a name="ln-588"></a><span class="k">subroutine </span><span class="n">get_lattice_link</span><span class="p">(</span><span class="n">T</span><span class="p">,</span><span class="n">L</span><span class="p">)</span>
<a name="ln-589"></a>
<a name="ln-590"></a>	<span class="k">class</span><span class="p">(</span><span class="n">tn_tensor</span><span class="p">),</span><span class="k">target</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">in</span><span class="p">)</span><span class="kd">::</span><span class="n">T</span>
<a name="ln-591"></a>	<span class="k">type</span><span class="p">(</span><span class="n">lattice</span><span class="p">),</span><span class="k">pointer</span><span class="p">,</span><span class="k">intent</span><span class="p">(</span><span class="n">inout</span><span class="p">)</span><span class="kd">::</span><span class="n">L</span>
<a name="ln-592"></a>
<a name="ln-593"></a>	<span class="k">call </span><span class="n">T</span><span class="p">%</span><span class="n">grp</span><span class="p">%</span><span class="n">get_lattice_link</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
<a name="ln-594"></a>
<a name="ln-595"></a><span class="k">end subroutine</span>
<a name="ln-596"></a>
<a name="ln-597"></a><span class="k">end module </span><span class="n">tn_tensor_type</span>
</pre></div>

    </section>
    </div>
  </div>

  
    <hr>    
    </div> <!-- /container -->
    <footer>
      <div class="container">
      <div class="row">
        <div class="col-xs-6 col-md-4"><p>&copy; 2019 <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/80x15.png" /></a>
                                          </p></div>
        <div class="col-xs-6 col-md-4 col-md-push-4">
          <p class="text-right">
            Documentation generated by 
            <a href="https://github.com/cmacmackin/ford">FORD</a>
            
          </p>
        </div>
        <div class="col-xs-12 col-md-4 col-md-pull-4"><p class="text-center"> TNSG was developed by Wang Chao & Dong Shaojun</p></div>
      </div>
      <br>
      </div> <!-- /container -->    
    </footer>

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
<!--
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
-->
    <script src="../js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../js/ie10-viewport-bug-workaround.js"></script>

    <!-- MathJax JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } },
        jax: ['input/TeX','input/MathML','output/HTML-CSS'],
        extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']
      });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    
    
  </body>
</html>