2016.5.22
		make the name of the Type bound procedres in Dimension.f90 be the same as that in Tensor.f90
	 		fuse , split in type(dimension)
	 		
	 		
	 		
2016.5.23
		add some  Type bound procedres  to type(dimension), they are
		     %dim()
		     %outName()
		     %outTensorName()
		     %restDim()
		add some operator to type(dimension), they are
		     .fuse.
		     .split.
		     .dim.
		     .subdim.
		     .iname.
		     .iiname.
		     .Tname.



2016.5.25
		modify the function of dimension.f90
			.fuse.  if input is a empty dimension, output a empty dimension
			%fuse   if input is a empty dimension, do nothing
		modify the function of Tensor.f90
			.fuse.  if input is a empty Tensor, output a empty Tensor
			%fuse   if input is a empty Tensor, do nothing



2016.5.28
      modify the code in Tensor.f90:
      
				if(.not.(if_original_dim(T1_%TenDim).and.if_original_dim(T2_%TenDim))) then
						write(*,*)"ERROR in Tenproduct"
						write(*,*)"stop"
						call error_stop()
				end if
      All the permutation suppose the Tensor that is not original form, this code is useless
      Howere if contract using name, these lines are uesful


2016.5.31
		 modify the code in Tensor.f90:
		 		1.Delete the %sub
		 		2.pasteTensor is a subroutine not a function
		 		3.addRow and AddCol is a subroutine not a function
		 		4. (.Rpaste.) (.CPaste.) is a operator use as pasteTensor
		 		5. (.addRow.) (.AddCol.) is a operator use as AddRow and AddCol
		 		
		 		
		 		




2016.6.11
      Define all the parameter and other common data at the beginning of function.f90




2016.6.12
		 The Type bound procedres in Tensor, SVD  change to  SVDTensor
		 inv change to invTensor
		 eig change to eigTensor


2016.6.13
		(.p.) (.pf.) (.pb.) suppose the Tensor to specify the new order
		%forward() %permute() %backward() suppose the Tensor to specify the new order
		The Tensor use as input parameter that specify new order can be integer Tensor or character Tensor
		


2016.6.15
		SVD will out put error log in ./_SVD_ERROR_LOG.err if there is error
		 	


2016.6.15
		New operator of .kron. that support the direct product for any rank Tensor. see more in help/operator/korn


2016.7.1
		ERROR output in contracting Tensor. If one of or both of the input Tensors are empty, then report error and error stop




2016.7.11
     Update %invTensor with:
            A=B%invTensor(RCOND):
            if B^{-1} may not exit,input RCOND, it is class(*)
				perform SVD on B, Only keep  singular values S(i) <= RCOND*S(1) 
				if RCONDM<0 keep the S(i)>0

2016.7.14
     Updata the error log of SVD, if the simgle value of the output is NAN, than output error log in ./_SVD_ERROR_LOG.err and stop


2016.7.16
       Updata the perfomace of LQ QR decomposion, but can not find the subroutine of  CORGQR or ZORGQR. The performance of complex
    and complex*16 is unchange.
    
      Fix bug in send of BCAST Tensor when Using MPI with mpi_comm_split:
         call sent_Tensor(T1,T2,ID1,ID2,ierr,MPI_COMM_T1)
         if there is no ID1 or ID2 in MPI_COMM_T1, return
      
      

2016.7.21
      Speed up A*B when there is only one element in A or B. Tensor.f90 TData.f90
      
      
2016.9.23
     Speed up A*B by 
     
     
         newD=D1.sub.1
			do i=2,rank1-1
				newD=newD+(D1.sub.i)
			end do
			
    modify as
			newD=D1.sub.[1,rank1-1]


2016.9.24
	sopport the function below in %setValue
		Tdata(i1:i2)=a(i1':i2') a is a Tensor or array  --- modify_Some_Data1_*
		Tdata(i1:i2,j1:j2)=a(i1':i2',j1':j2') a is a Tensor or array  --- modify_Some_Data2_*

2016.10.30
    speed up the assignment of Tensor T1=T2, if the totalData less than LAPACK_LENGTH, Do no use lapack
    speed up the T1*T2, if the totalData less than LAPACK_LENGTH, Do no use lapack


2016.11.8
   Add subroute of Tensor  T%sort
   
   
2016.11.24
	Add the subroutine call T%pointer(p), output p will pointer to the Tdata, one can modify the private data through this subroutine
	if T is of type character,  the pointer should be character(len=max_len_of_char_in_TData),pointer::p(:),p2(:,:)


2016.11.25
   Set the default value of random seed as 0
   
   
2016.11.26
    Add one more new data type named type(Parameter)



2016.11.28
    add check_same_name_flag in function.f90
    if check_same_name_flag=.true.  the program will check every dimension, the name in the dimension cannot be the same!
    if check_same_name_flag=.false. Do not check
    
    
    change the type(Para) ==>  type(List)  , this one sound better

2016.11.29
    add function enlargerTensor(ith,newD,randomscal) and subroutine T%enlarger(ith,newD,randomscal)
                 enlargerTensor(newDArray,randomscal) and subroutine T%enlarger(newDArrayrandomscal)
    enlarger the dimension of the Tensor, the newelement will set to a random number




2016.12.2
    modify T%pointer(p,[i1,i2]), it can pointer to the sub_element of the Tensor, it support p(:),p(:,:),p(:,:,:)



2016.12.3
    call T%diminfo() will print the data to the log
    modfy the error message of fTensor, it will output to the log
    
    New function of FindOrder, is the same as NameOrder but if the function can not find the name, error stop
    
    speed up the (*) of two type(SymTensor) By rewrite SGEMM
    
    speed up the (*) of two type(fTensor) by calling subroutine


2016.12.4
    New subroutine of killLeg,  T%killLeg(2),T%killLeg('A.b'),T%killLeg(),T%killLeg(2,'kill'),T%killLeg('A.b','kill')
    
        T%killLeg():  delete all the leg whose dimension is 1. example dimension of T is [2,1,1,1,1,2], output [2,2]
        T%killLeg(2): delete all the leg whose dimension is 1, except the 2rd leg. example dimension of T is [2,1,1,1,1,2], output [2,1,2]
        T%killLeg('A.b'): delete all the leg whose dimension is 1, except the one whose name is 'A.b'
        T%killLeg(2,'kill') delete the 2rd leg, if its dimension is 1
        T%killLeg(2,'kill') delete the leg whose name is 'A.b', if its dimension is 1



2016.12.10
    Add new function of SymTensor  
                  T%inorm()
                  T%snorm()
                  T%dnorm()
                  T%cnorm()
                  T%znorm()
                  T%inorm2()
                  T%snorm2()
                  T%dnorm2()
                  T%cnorm2()
                  T%znorm2()
                  
                  
2016.12.15
     The name of the module Tensor_complex change as Tensor_type




2016.12.26
     fix bug of Tensor/integer: T/i
        old code:
                1. i---> 1/i, change as real*4   -----> this make cause error
                2. T---> T *(1/i)
        new code
                1. i---> 1/i, change as real*8
                2. T---> T *(1/i)




2016.12.28
     New funciton of SymTensor:
                   T%sum
                   T%isum
                   T%ssum
                   T%dsum
                   T%csum
                   T%zsum


2016.12.29
     New fucntion of SVD:
          suppose the Name of T is ['A.1','A.2','A.3','B.1','B.2','C.1']
             SVD=T%SVDTensor(['B.1','B.2']) : 'B.1','B.2' will be row and other will be col and do the SVD
             SVD=T%SVDTensor(['B.1','B.2'],'c') 'B.1','B.2' will be col and other will be row and do the SVD, 'c' can be 'r' and specify row
             SVD=T%SVDTensor(['B.1','B.2'],['A.1','A.2','A.3','C.1'])
             call T%SVDTensor(U,s,V,['B.1','B.2'])
             call T%SVDTensor(U,s,V,['B.1','B.2'],'c')
             call T%SVDTensor(U,s,V,['B.1','B.2'],['A.1','A.2','A.3','C.1']) 

2016.12.31
     new subroutine of set_output_MPI_log('notOverWrite') or set_output_MPI_log()
     use after seting log for the program, and every cpus will write out the messages to its own log file


2017.1.13
     new function of T%subTensor
       A=T%subTensor(3,1,.true.)    : output subTensor of the 3th leg, the 1st dimension, and keep the leg
       A=T%subTensor(3,1)           : output subTensor of the 3th leg, the 1st dimension, and do not keep the leg
       A=T%subTensor('A.3',2,.true.): output subTensor of the leg whose name is 'A.3', the 3nd dimension, and keep the leg
       A=T%subTensor('A.3',2)       : output subTensor of the leg whose name is 'A.3', the 3nd dimension, and do not keep the leg
       A=T%subTensor(3,[1,2])       : output subTensor of the 3th leg, the 1st to 2nd dimension.
       A=T%subTensor('A.3',[2,3])   : output subTensor of the leg whose name is 'A.3', the 2nd to 3rd dimension.
      NOTE: can not work on the rank-1 Tensor
    
     new function of QR:(to be test more )
            suppose the Name of T is ['A.1','A.2','A.3','B.1','B.2','C.1']
             QR=T%QRTensor(['B.1','B.2']) : 'B.1','B.2' will be row and other will be col and do the QR
             QR=T%QRTensor(['B.1','B.2'],'c') 'B.1','B.2' will be col and other will be row and do the QR, 'c' can be 'r' and specify row
             QR=T%QRTensor(['B.1','B.2'],['A.1','A.2','A.3','C.1'])
             call T%QRTensor(U,s,V,['B.1','B.2'])
             call T%QRTensor(U,s,V,['B.1','B.2'],'c')
             call T%QRTensor(U,s,V,['B.1','B.2'],['A.1','A.2','A.3','C.1']) 
     
     
     new function of LQ:(to be test more)
            suppose the Name of T is ['A.1','A.2','A.3','B.1','B.2','C.1']
             LQ=T%LQTensor(['B.1','B.2']) : 'B.1','B.2' will be row and other will be col and do the LQ
             LQ=T%LQTensor(['B.1','B.2'],'c') 'B.1','B.2' will be col and other will be row and do the LQ, 'c' can be 'r' and specify row
             LQ=T%LQTensor(['B.1','B.2'],['A.1','A.2','A.3','C.1'])
             call T%LQTensor(U,s,V,['B.1','B.2'])
             call T%LQTensor(U,s,V,['B.1','B.2'],'c')
             call T%LQTensor(U,s,V,['B.1','B.2'],['A.1','A.2','A.3','C.1']) 
             
             
     new operator(+) for List: combine two list
     
     new function for List:  suppose the data in List are [12,34,56,78,90,123,123],['A','B','C','D','E','F','G']
              List=List2%sub(2,4) :output the 2nd to 4th sub list:[34,56,78],['B','C','D']
              List=List2%sub('B','D'):output sub list:[34,56,78],['B','C','D']



2017.1.14
    modify QR and LQ for complex number use CUNGLQ ZUNGLQ CUNGQR ZUNGQR in TData.f90.


2017.1.16
    New type of memory has been written in function.f90
    
    modify the function in TData.f90,use the type(memory): 
    		TData_QR
    		TData_LQ
    		TData_ORGQR
    		TData_ORGLQ
    		SVD_TData_routine
    		permutation_data3_inout
    		permutation_data2_inout


2017.1.17
    fix bug in MPI_x_Tensor when Tensor is complex*16, where x stand for MAX, MIN, SUM, send and so on. The bug report by Chao Wang(wang1329@mail.ustc.edu.cn)
    
        call MPI_ALLREDUCE(inTData%zdata,outTData%zdata,2*inTData%totalData,MPI_complex,MPI_SUM,mpi_comm,ierr)
    change as 
        call MPI_ALLREDUCE(inTData%zdata,outTData%zdata,inTData%totalData,MPI_double_complex,MPI_SUM,mpi_comm,ierr)
        
    fix bug in complex*16 Tensor, when call MPI_MAX_Tesnor, MPI_MIN_Tesnor, report error


2017.1.21
    New function in Tensor: 
       
     1. call T%ProductTensorRoutine(A,B,alpha,beta): T=alpha * (A * B) + Beta *T
          if T is a empty Tensor, allocate memory for T
  NOTE:  other while WILL NOT allocate memory or change the dimension of T !!!!!!!!!!!!!!!

     2. call T%ProductTensorRoutine(A,B,alpha): T=alpha * (A * B) 
  NOTE:  other while WILL  allocate memory or change the dimension of T !!!!!!!!!!!!!!!

  

     3. call T%contract(A,[legnames],B,[legnames],len): the same as T=contract(A,[legnames],B,[legnames],len)
  NOTE: This routine will reorder the dimenison of both A and B, but will not change the value.


2017.1.22

   Modify function in Dimension.f90: the allocatable data replace by pointer that use the WorkingMemory
   
      1. Dimpermute_forwards:
               integer,allocatable::order(:) ----> integer,pointer::order(:)
      2.Dimpermute_backwards
               integer,allocatable::order(:) ----> integer,pointer::order(:)
      3.Dimpermute_backwards_index
               integer,allocatable::order(:) ----> integer,pointer::order(:)
      4.Dimpermute_forwards_index
               integer,allocatable::order(:) ----> integer,pointer::order(:)
      5.Dimpermute_backwards
               integer,allocatable::order(:) ----> integer,pointer::order(:)
               
               
2017.1.23

   Modify function in Tensor.f90, use the workingmemory instead of allocatable array. The functions have been changed are:           
      
       1. contract
       2. productTensor
       3. productTensorRoutine
       4. permutation
   
   Modify the error message, the program will use the invalid memory reference to Backtrace for the error.
   
   New type of extendsMemory has been written in Tensor.f90



2017.1.24
   
   1.New function of 
         
         Working_memory_report,Tensor_memory_report,Tensor_memory_length
         TData_memory_report,TData_memory_length
         Dimension_memory_report,Dimension_memory_length
   
      They are used for reporting the memory used in the files. And call Working_memory_report() will report all the thing
   
   2. call set_deallocate_memory_flag()   :          deallocate memory for assignment and working memory
      call unset_deallocate_memory_flag() :  DO NOT  deallocate memory for assignment or working memory
      
2017.1.25

    New function for T%contract:
    
      1.call T%contract(A,[legnames1],B,[legnames2],len): the same as T=contract(A,[legnames1],B,[legnames2],len)
  NOTE: This routine will reorder the dimenison of both A and B, but will not change the value.
      2.call T%contract([legnames1],B,[legnames2],len): the same as T=contract(T,[legnames1],B,[legnames2],len)
  NOTE: This routine will reorder the dimenison of both A and B, but will not change the value.
      3.call T%contract(A,[legnames1],[legnames2],len): the same as T=contract(A,[legnames1],T,[legnames2],len)
  NOTE: This routine will reorder the dimenison of both A and B, but will not change the value.



    Fix bugs in T%contract


2017.1.27

    Fix bug of diminfo() report by Chao Wang(wang1329@mail.ustc.edu.cn). This bug will not cause the error of the program.
    

2017.2.22


   Add the error messages in 
              
            1. call T%contract(A,[names1],B,[names2])
            2. call T%contract([names1],B,[names2])
            3. call T%contract(A,[names1],[names2])
  where A,B and T can not be the same variable


    code change in  T%contract(A,[names1],[names2]),T%contract([names1],B,[names2])

                   the input A and B are class(Tensor)
  
  
  
  Add the error messages in T%QRroutine  T%LQroutine  T%SVDroutine:
    
          All the input and output Tensors can not be the same variable



2017.2.25

  Add the error messages in T% ProductTensorRoutine:
    
          All the input and output Tensors can not be the same variable


2017.2.27
   
   modify error message, output the running cpu number when running the MPI


2017.2.27

    New function for T%contract:
    
      1.call T%contract(A,name1,B,name2): the same as T=contract(A,name1,B,name2)
  NOTE: This routine will reorder the dimenison of both A and B, but will not change the value.
      2.call T%contract(name1,B,name2): the same as T=contract(T,name1,B,name2)
  NOTE: This routine will reorder the dimenison of both A and B, but will not change the value.
      3.call T%contract(A,name1,name2): the same as T=contract(A,[legnames1],T,name2)
  NOTE: This routine will reorder the dimenison of both A and B, but will not change the value.

2017.3.5

    Fix bug in call T%readData(unit)
       read the data from outside file, and only allow for rank-2 tensor for the moment


2017.3.9

    Add now function to TData.f90:product_MM_dim1_parameter for the now subroutine in Tensor.f90:ProductTensorRoutine3. Do not OK yet
    
2017.3.24

    Fix bug of Tensor/int Tensor/real(kind=4) when Tensor is single real of single complex type, this bug will lead to the error of expm(Tensor).



2017.5.5

       Modify the code in Tensor.f90: contract_name_routine,contract_name_routine1,contract_name_routine2,contract_name_routine3,contract_name_routine4
    contract_name_routine5 and contract_name_routine6
       The input and output Tensor
       
       
         class(Tensor),target,intent(inout)::T    =====>  class(Tensor),target::T
         class(Tensor),target,intent(inout):: T1  =====>  class(Tensor),target::T1
         class(Tensor),target,intent(inout):: T2  =====>  class(Tensor),target::T2
2017.5.9


      Add new function of l=T%ifName(w,ch), return true if there is a leg named w in the dimension
      	l=T%ifName('A','Tensor'): if there is a legs(or some legs) whoes TensorName is 'A', return .true.
      	l=T%ifName('A')         : if there is a legs(or some legs) whoes DimensionName is 'A', return .true.
      	l=T%ifName('A.a')       : if there is a legs(or some legs) whoes name is 'A.a', return .true.
    
2017.5.16

      Add new function of list%findValue(inputlist)
      and other new funciton:
                       
                       call list%setvalue(vector) ,list can be a empty list or a allocated list
                       call list%setvalue(Tensor) ,list can be a empty list or a allocated list

2017.5.27

     Fix bug of T%max()
                T%min()
                
                
                outvalue=maxval(T%?data) --> outvalue=maxval(T%?data(1:T%totalData))
       
2017.6.5


	T%enlarger and T%enlargerTensor can be call by TensorName
	            
	            call T%enlarger('T.dimension',1d0)
	            A=B%%enlargerTensor('T.dimension',1d0)


2017.6.6
   
     New module of OtherFunction
           new suubroutine ALLREDUCE_Tensor(inTensor,outTensor,OP,ierr,MPIcommon) 
     














































